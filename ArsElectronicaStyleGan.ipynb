{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of ArsElectronicaStyleGan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artjing/2019Projects.github.io/blob/master/ArsElectronicaStyleGan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz6wRvFxLdqY"
      },
      "source": [
        "#Style Transfer\n",
        "Style transfer is the process of applying one texture (the Style image) to the content of another image (the Content image). You probably saw it a few years ago when there were a bunch of apps that would convert your selfies to Starry Night images. It quickly (immediately?) became cliché and made style transfer look like a fad, but I maintain style transfer is a really cool tool in the hands of artists.\n",
        "\n",
        "Here’s a quick demo of how to make your own style transfers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml04N83FROe-"
      },
      "source": [
        "##Set up our Runtime\n",
        "Colab needs to know we need to use a GPU-powered machine in order to do style transfers. At the top of this page, click on the `Runtime` tab, then select `Change runtime type`. In the modal that pops up, select `GPU` under the `Hardware accelerator` options.\n",
        "\n",
        "We then need to make sure we’re using the latest version of Tensorflow 1, otherwise we get some annoying messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BMdAScclQVN"
      },
      "source": [
        "#install TF 1.15 to avoid some annoying warning messages\n",
        "# Restart runtime using 'Runtime' -> 'Restart runtime...'\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec_j9q3XLtBE"
      },
      "source": [
        "##Install the neural-style-tf library\n",
        "We’re going to work with the library called Neural Style. This is a version I’ve customized to do a couple things that I think are helpful for artists.\n",
        "\n",
        "In the next cell, type `Shift+Return` to run the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmjBZZLbLb-2"
      },
      "source": [
        "#import some image display tools\n",
        "from IPython.display import Image, display\n",
        "#install the library in colab\n",
        "!git clone https://github.com/dvschultz/neural-style-tf\n",
        "#change into that directory\n",
        "%cd neural-style-tf/\n",
        "#install the library dependencies (it's likely Colab already has them installed, but let's be sure)\n",
        "!pip install -r requirements.txt\n",
        "#install the VGG19 pre-trained model\n",
        "!wget http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3FTtdkSL_lV"
      },
      "source": [
        "#let's make sure we're in the right folder\n",
        "!pwd\n",
        "# we should see \"/content/neural-style-tf\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo4znFOlNyig"
      },
      "source": [
        "if you got `/content/neural-style-tf` you’re all set to do your first style transfer\n",
        "\n",
        "##A Basic Style Transfer\n",
        "To make sure everything is working as expected, let’s run a basic style transfer using the images this library already provides.\n",
        "\n",
        "First, let’s look at the folder setup. To the left of this text, click on the right pointing caret/arrow. That opens the Table of contents for this notebook. Click on the `Files` tab. This is a view of our \"server.\" click on the arrow/twirley next to `neural-style-tf`. Then do the same for the `image_input` and `styles` folders. These two folders map to the Content (`image_input`) and Style (`styles`) images. I’m going to pick the lion from the content folder and the kandinsky from the styles folder.\n",
        "\n",
        "There are two arguments required for the basic `neural_style.py` script:\n",
        "\n",
        "\n",
        "*   `--content_img`: the content image filename plus extension\n",
        "*   `--style_imgs`: the style image filename plus extension\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4Ytyol6XogB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld0p1SkgN2MN",
        "outputId": "7a59fdf9-30f3-45af-e288-4e937ac46caa"
      },
      "source": [
        "!python neural_style.py --content_img 0.png --style_imgs 1.png --max_size 1000 --img_output_dir ./image_output1.1\n",
        "# !python neural_style.py --content_img 0.png --style_imgs 2.png --max_size 1000 --img_output_dir ./image_output1.2\n",
        "# !python neural_style.py --content_img 0.png --style_imgs 3.png --max_size 1000 --img_output_dir ./image_output1.3\n",
        "# !python neural_style.py --content_img 0.png --style_imgs 4.png --max_size 1000 --img_output_dir ./image_output1.4\n",
        "# !python neural_style.py --content_img 0.png --style_imgs 5.png --max_size 1000 --img_output_dir ./image_output1.5\n",
        "\n",
        "# !python neural_style.py --content_img 00.png --style_imgs 1.png --max_size 1000 --img_output_dir ./image_output2.1\n",
        "# !python neural_style.py --content_img 00.png --style_imgs 2.png --max_size 1000 --img_output_dir ./image_output2.2\n",
        "# !python neural_style.py --content_img 00.png --style_imgs 3.png --max_size 1000 --img_output_dir ./image_output2.3\n",
        "# !python neural_style.py --content_img 00.png --style_imgs 4.png --max_size 1000 --img_output_dir ./image_output2.4\n",
        "# !python neural_style.py --content_img 00.png --style_imgs 5.png --max_size 1000 --img_output_dir ./image_output2.5\n",
        "\n",
        "#style_scale = 1.0 (default)\n",
        "#!python neural_style.py --content_img 1.png --style_imgs 4.png --max_size 1000 --max_iterations 500 --style_scale 1.0 --img_output_dir ./image_output1.0\n",
        "#style_scale = 0.75\n",
        "#!python neural_style.py --content_img 1.png --style_imgs 1.png --max_size 1000 --max_iterations 500 --style_scale .75 --img_output_dir ./image_output0.75\n",
        "#style_scale = 0.5\n",
        "#!python neural_style.py --content_img 1.png --style_imgs 1.png --max_size 1000 --max_iterations 500 --style_scale 0.5 --img_output_dir ./image_output0.5\n",
        "#style_scale = .25\n",
        "#!python neural_style.py --content_img 1.png --style_imgs 1.png --max_size 1000 --max_iterations 500 --style_scale .25 --img_output_dir ./image_output0.25"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---- RENDERING SINGLE IMAGE ----\n",
            "\n",
            "2021-11-12 17:48:29.292605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-11-12 17:48:29.305337: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-11-12 17:48:29.305392: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6ee1f836a34c): /proc/driver/nvidia/version does not exist\n",
            "2021-11-12 17:48:29.311072: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-11-12 17:48:29.311373: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f57e522bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-12 17:48:29.311412: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:From neural_style.py:333: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1348, in _run_fn\n",
            "    self._extend_graph()\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1388, in _extend_graph\n",
            "    tf_session.ExtendSession(self._session)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Variable: {{node Variable}} was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\n",
            "\t [[Variable]]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"neural_style.py\", line 889, in <module>\n",
            "    main()\n",
            "  File \"neural_style.py\", line 886, in main\n",
            "    else: render_single_image()\n",
            "  File \"neural_style.py\", line 855, in render_single_image\n",
            "    stylize(content_img, style_imgs, init_img)\n",
            "  File \"neural_style.py\", line 566, in stylize\n",
            "    L_style = sum_style_losses(sess, net, style_imgs)\n",
            "  File \"neural_style.py\", line 418, in sum_style_losses\n",
            "    sess.run(net['input'].assign(img))\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation Variable: node Variable (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748)  was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\n",
            "\t [[Variable]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ACxas0eqC-k"
      },
      "source": [
        "\n",
        "!python neural_style.py --content_img 2.png --style_imgs 2.png --max_size 1000 --max_iterations 500 --style_scale 1.0 --img_output_dir ./2image_output1.0\n",
        "#style_scale = 0.75\n",
        "#style_scale = .25\n",
        "!python neural_style.py --content_img 2.png --style_imgs 2.png --max_size 1000 --max_iterations 500 --style_scale .25 --img_output_dir ./2image_output0.25\n",
        "\n",
        "\n",
        "!python neural_style.py --content_img 3.png --style_imgs 3.png --max_size 1000 --max_iterations 500 --style_scale 1.0 --img_output_dir ./3image_output1.0\n",
        "#style_scale = .25\n",
        "!python neural_style.py --content_img 3.png --style_imgs 3.png --max_size 1000 --max_iterations 500 --style_scale .25 --img_output_dir ./3image_output0.25\n",
        "\n",
        "#style_scale = 1.0 (default)\n",
        "!python neural_style.py --content_img 4.png --style_imgs 4.png --max_size 1000 --max_iterations 500 --style_scale 1.0 --img_output_dir ./4image_output1.0\n",
        "#style_scale = .25\n",
        "!python neural_style.py --content_img 4.png --style_imgs 4.png --max_size 1000 --max_iterations 500 --style_scale .25 --img_output_dir ./4image_output0.25\n",
        "\n",
        "#style_scale = 1.0 (default)\n",
        "!python neural_style.py --content_img 5.png --style_imgs 5.png --max_size 1000 --max_iterations 500 --style_scale 1.0 --img_output_dir ./5image_output1.0\n",
        "\n",
        "!python neural_style.py --content_img 5.png --style_imgs 5.png --max_size 1000 --max_iterations 500 --style_scale .25 --img_output_dir ./5image_output0.25\n",
        "\n",
        "#style_scale = 1.0 (default)\n",
        "!python neural_style.py --content_img 6.png --style_imgs 6.png --max_size 1000 --max_iterations 500 --style_scale 1.0 --img_output_dir ./6image_output1.0\n",
        "!python neural_style.py --content_img 6.png --style_imgs 6.png --max_size 1000 --max_iterations 500 --style_scale .25 --img_output_dir ./6image_output0.25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Hwtv9LcudY"
      },
      "source": [
        "!python neural_style.py --content_img 1.png --style_imgs 1.png --max_size 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPgimcD7THPK"
      },
      "source": [
        "This may take a couple minutes to run, but if you see `Single image elapsed time: [some number]` then it has completed.\n",
        "\n",
        "Let’s take a look at the content image, the style image, and what it combined to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGeMTBeSP5GO"
      },
      "source": [
        "listOfImageNames = ['image_output/1000/content.png',\n",
        "                    'image_output/1000/style_0.png',\n",
        "                    'image_output/1000/image_output-1000.png']\n",
        "\n",
        "for imageName in listOfImageNames:\n",
        "    display(Image(filename=imageName))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0_EXYQrULo2"
      },
      "source": [
        "Using just this command you can now create custom style transfers. Upload a content image and style image into the correct folders in the panel to the left. Right click on each folder and choose `Upload`. **Important**: Anytime you restart your runtime, any files you upload (or create!) will be destroyed. Don’t lose your work!\n",
        "\n",
        "Once your files are uploaded, edit the next cell with the image filenames you uploaded. Once edited, press `Shift+Return` to run the command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lpklbQxSjSb"
      },
      "source": [
        "!python neural_style.py --content_img {content filename} --style_imgs {style filename}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SzHf1CIXM-2"
      },
      "source": [
        "Let’s see what you made. If you want to display the image in this notebook, just edit the following cell to point to the correct image path. You can get the image path by right-clicking on the completed image in the `Files` tab and selecting `Copy path`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ogQiDsXo8D"
      },
      "source": [
        "Image(filename='{path/to/image}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIYFhN48YA7x"
      },
      "source": [
        "Like what you made and want to download it? There are two ways:\n",
        "\n",
        "\n",
        "1.   Right-click on the image in the `Files` tab, and choose `Download`\n",
        "2.   Put that file path you grabbed from above into the cell below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR0V-X-_HSCm"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEjitx5pYO5u"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('{path/to/image}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVftUtSkYbep"
      },
      "source": [
        "This concludes the basic style transfer demo. To be fair, you could do this with any number of online apps. The **real** power is in all of the options this library has to tweak various parts of the style tranfer effect.\n",
        "\n",
        "##Style Transfer: Options\n",
        "Let’s look at a couple options we might want to use immediately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4OXoponf82V"
      },
      "source": [
        "###Output Size\n",
        "If you notice, both the Lion image and the Kandinsky image are at least 1000px in size, but your output style transfer is 512px. What if you want a bigger image? This particular library’s default rendering size is 512, but you can override that to any* size you want.\n",
        "\n",
        "*ok, you can’t really do _any_ size. First, I wouldn’t recommend making the output image larger than either image as it will lead to some pixelation. Second, the larger the image is the longer and more processor intensive the operation will be. In a notebook on Colab, you might not be able to get much larger than 750px. On the P5000 we use on Paperspace you can often get up to 1200 or 1400px depending on the image ratio.\n",
        "\n",
        "Let’s try something a little larger. And let’s use the lion and kandinsky again. We’ll add the `--max_size` argument, and pass it an integer for the longest dimension (if we want 1200pixels, we use `1200`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTyX18mcZHYp"
      },
      "source": [
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ_UQxvnckKq"
      },
      "source": [
        "Let’s look at what we made. (Note: this may have just overwritten the previous image.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEbKK08kaQqJ"
      },
      "source": [
        "Image(filename='/content/neural-style-tf/image_output/1000/image_output-1000.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtG3JluUc_Wd"
      },
      "source": [
        "That’s definitely bigger!\n",
        "\n",
        "From now on I’m actually going to use a smaller size than the library defaults to. This will help generate the images quicker. But know you can always edit this argument at any time and re-run it.\n",
        "\n",
        "###Iterations\n",
        "\n",
        "I compare iterations to \"baking time.\" If you underbake something it comes out mushy and inedible. If you overbake something it comes out hard or burned. What’s the right baking time? Well, it depends on the item you’re baking! And in this case it also depends on you, the baker. Or artist—this metaphor only needs to go so far.\n",
        "\n",
        "To change the iterations we’ll use the `--max_iterations` argument. It defaults to 1000. Let’s look at a couple different versions to compare them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2_0gIDwc8zG"
      },
      "source": [
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 100\n",
        "Image(filename='/content/neural-style-tf/image_output/100/image_output-100.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84R4pq-peE8S"
      },
      "source": [
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 500\n",
        "Image(filename='/content/neural-style-tf/image_output/500/image_output-500.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oj1JlsYekXx"
      },
      "source": [
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 800\n",
        "Image(filename='/content/neural-style-tf/image_output/800/image_output-800.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0BinXTTfFCW"
      },
      "source": [
        "You may have noticed the more iterations, the longer it takes to generate the image.\n",
        "\n",
        "Let’s look at the images side by side."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teztutSreyPR"
      },
      "source": [
        "listOfImageNames = ['image_output/100/image_output-100.png',\n",
        "                    'image_output/500/image_output-500.png',\n",
        "                    'image_output/800/image_output-800.png',]\n",
        "\n",
        "for imageName in listOfImageNames:\n",
        "    display(Image(filename=imageName))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhgkFMjtfldb"
      },
      "source": [
        "It’s not always easy to tell the difference and it can depend a lot on the images you’re using, but I personally find 1000 iterations to be the top of what I find useful. I usually use 400 or 500 most times and like that setting—it may be different for you and your images. It’s worth playing with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTWg2td2gIct"
      },
      "source": [
        "###Folder Naming\n",
        "You’ll notice the folders come with default names. For now that’s fine, but as you do more and more of these it will get really confusing to find the image you want to download. I try to name my folders descriptively so that I can also redo an image if I like it.\n",
        "\n",
        "For this, we’ll use the `--img_output_dir` argument. (Note that in my version of this library it will use this for both the name of the folder and the name of the output image.)\n",
        "\n",
        "**Important:** if you use the same folder name twice it will override the previous generated image. Make sure you edit this every time you make a new image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy9fPIsBfeWN"
      },
      "source": [
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 500 --img_output_dir ./lion-kandinksy-256sz-500iter\n",
        "Image(filename='/content/neural-style-tf/lion-kandinksy-256sz-500iter/500/lion-kandinksy-256sz-500iter-500.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHPQH7Z8hscj"
      },
      "source": [
        "###Multiple Style Images\n",
        "OK, let’s start having fun and get into some advanced style transfer things. What if we want _multiple_ styles? Almost like a collage or something. In all those online apps, you really only get one style. But we can do two, three, four! styles in this library by passing in multiple file names using the `--style_imgs` argument.\n",
        "\n",
        "whenever you use multiple style images, you also need to add and edit the `--style_imgs_weights` argument. This argument allows you to assign how much of each style image comes into the image (it should always add up to 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJqRvPONg_Vr"
      },
      "source": [
        "#evenly weighted style images\n",
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg starry-night.jpg --max_size 256 --max_iterations 500 --style_imgs_weights 0.5 0.5 --img_output_dir ./lion-kandinksy+starrynight-256sz-500iter\n",
        "Image(filename='/content/neural-style-tf/lion-kandinksy+starrynight-256sz-500iter/500/lion-kandinksy+starrynight-256sz-500iter-500.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc3AhqT2i3NS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIZgAfrAiZFZ"
      },
      "source": [
        "#this version weights toward the starry night image\n",
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg starry-night.jpg --max_size 256 --max_iterations 500 --style_imgs_weights 0.25 0.75 --img_output_dir ./lion-kandinksy+starrynight-256sz-500iter-w.25-.75\n",
        "Image(filename='/content/neural-style-tf/lion-kandinksy+starrynight-256sz-500iter-w.25-.75/500/lion-kandinksy+starrynight-256sz-500iter-w.25-.75-500.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSIt0eIDmZJT"
      },
      "source": [
        "###Style Scale\n",
        "One of my favorite options is to use the `-style_scale` argument.\n",
        "\n",
        "When the default style transfer script is run it crops the style image to the same size as the content image and uses the exact same scale. Sometimes this means the style isn’t represented well and the detail of the style texture doesn’t match our expectations. But we can scale the style image to try to retain some of those textural elements.\n",
        "\n",
        "Here we’ll look at a couple different scales of the Kandinksky image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4VIYGvDnZra"
      },
      "source": [
        "#style_scale = 1.0 (default)\n",
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 500 --style_scale 1.0 --img_output_dir ./lion-kandinksy-256sz-500iter-scale1.0\n",
        "#style_scale = 0.75\n",
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 500 --style_scale .75 --img_output_dir ./lion-kandinksy-256sz-500iter-scale0.75\n",
        "#style_scale = 0.5\n",
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 500 --style_scale 0.5 --img_output_dir ./lion-kandinksy-256sz-500iter-scale0.5\n",
        "#style_scale = .25\n",
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 500 --style_scale .25 --img_output_dir ./lion-kandinksy-256sz-500iter-scale0.25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKwB8jx4pI1t"
      },
      "source": [
        "Let’s look at all of these next to each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmUOLlVtpNxk"
      },
      "source": [
        "listOfImageNames = ['/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale1.0/500/lion-kandinksy-256sz-500iter-scale1.0-500.png',\n",
        "                    '/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale0.75/500/lion-kandinksy-256sz-500iter-scale0.75-500.png',\n",
        "                    '/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale0.5/500/lion-kandinksy-256sz-500iter-scale0.5-500.png',\n",
        "                    '/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale0.25/500/lion-kandinksy-256sz-500iter-scale0.25-500.png']\n",
        "\n",
        "for imageName in listOfImageNames:\n",
        "    display(Image(filename=imageName))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTJvin3BqQgz"
      },
      "source": [
        "As you can see, the smaller the scale the more details included in the final image. It’s another parameter that comes down to personal preference.\n",
        "\n",
        "You can also look at what the scale image looks like when passed to the style transfer script by looking at the `style_0.png` image (in the case of multiple style images, each will be numberd)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFvgVs8jqp1R"
      },
      "source": [
        "listOfImageNames = ['/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale1.0/500/style_0.png',\n",
        "                    '/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale0.75/500/style_0.png',\n",
        "                    '/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale0.5/500/style_0.png',\n",
        "                    '/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale0.25/500/style_0.png']\n",
        "\n",
        "for imageName in listOfImageNames:\n",
        "    display(Image(filename=imageName))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOSBup4cwsrq"
      },
      "source": [
        "###Original Colors\n",
        "Another interesting feature of this library is the ability to use the color from the content image and only take the texture (and not the color) from the style image.\n",
        "\n",
        "To do this you just pass the `--original_colors` argument. Unlike other arguments where you need to pass in parameters, `--original_colors` just needs to be passed without anything else.\n",
        "\n",
        "Here’s we’ll run it with the lion image, which was originally grayscale. I recommend trying it with some other images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zBiCVi6rWmU"
      },
      "source": [
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 500 --style_scale 0.5 --original_colors --img_output_dir ./lion-kandinksy-256sz-500iter-scale0.5-originalcolors\n",
        "Image(filename='/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale0.5-originalcolors/500/lion-kandinksy-256sz-500iter-scale0.5-originalcolors-500.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRigX_a47em"
      },
      "source": [
        "###Content and Style Weights\n",
        "Sometimes a style transfer just isn’t working. Maybe the textures aren’t coming through enough, or the style is making the image hard to read. One solution is to adjust the weights of the content and style. We do this by altering the `--content_weight` and the `--style_weight` arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWbOdM4S5UuH"
      },
      "source": [
        "#This example will emphasize the content more (we leave the content weight at its default and turn down the style weight)\n",
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 500 --style_scale 0.5 --style_weight 1e2 --img_output_dir ./lion-kandinksy-256sz-500iter-scale0.5-styleweight1e2\n",
        "Image(filename='/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale0.5-styleweight1e2/500/lion-kandinksy-256sz-500iter-scale0.5-styleweight1e2-500.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKirrBvs6J3O"
      },
      "source": [
        "#This example will emphasize the style more (we leave the style weight at its default and turn down the content weight)\n",
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 500 --style_scale 0.5 --content_weight 3e0 --img_output_dir ./lion-kandinksy-256sz-500iter-scale0.5-contentweight3e0\n",
        "Image(filename='/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale0.5-contentweight3e0/500/lion-kandinksy-256sz-500iter-scale0.5-contentweight3e0-500.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKXKnLf9wnew"
      },
      "source": [
        "###Texture Synthesis\n",
        "You might now be thinking \"what if I turn the `content_weight` all the way down to zero?\" Well that isn’t really a form of style transfer but rather a \"hack\" to create interesting textures, a thing in Computer Vision called \"texture synthesis.\"\n",
        "\n",
        "We already looked at the `--content_weight` argument to adjust the content. Now we also need to pass `--init_img_type random` so that it starts with random noise (instead of the default, which is to start with the content image). Let’s look at an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U5cLluHjz5a"
      },
      "source": [
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 500 --style_scale 0.5 --content_weight 0e0 --init_img_type random --img_output_dir ./lion-kandinksy-256sz-500iter-scale0.5-0content\n",
        "Image(filename='/content/neural-style-tf/lion-kandinksy-256sz-500iter-scale0.5-0content/500/lion-kandinksy-256sz-500iter-scale0.5-0content-500.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFwSCnKM2aEF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFPwHyU1JaNR"
      },
      "source": [
        "#Homework Assignment\n",
        "Your homework:\n",
        "\n",
        "\n",
        "1.   Find a new content image and one (or multiple!) style images. You could use some of your own images, use Google search, Pinterest, or another search service.\n",
        "2.   Place those new images in the correct folder in the `Files` tab\n",
        "3.   Edit the script below to make an style transfer image using your new assets (feel free to edit other arguments as well)\n",
        "4.   Run the script to make your new image\n",
        "5.   Download your generated image and post it in our Slack group.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C5WSmLiKZ4m"
      },
      "source": [
        "!python neural_style.py --content_img lion.jpg --style_imgs kandinsky.jpg --max_size 256 --max_iterations 500 --style_scale 1.0 --img_output_dir ./lion-kandinksy-256sz-500iter-scale1.0"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}